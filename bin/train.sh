
#!/usr/bin/env bash

export USER=dixin
export hadoop=/home/work/hadoop2.7.1_dixin/bin/hadoop
export py2env=/data/dixin/python/py2env/bin/activate
export HOME=/data/${USER}/im2txt/

today_time=$(date --date="0 day" +"%m%d")
yesterday_time=$(date --date="-1 day" +"%m%d")
last_time=$(date --date="-2 day" +"%m%d")
visit_date=$(date --date="0 day" +"%Y%m%d")
last_date=$(date --date="-1 day" +"%Y%m%d")


# Directory containing preprocessed MSCOCO data.
MSCOCO_DIR="${HOME}/im2txt/data/mscoco"
if [ ! -d "${MSCOCO_DIR}" ]; then
  mkdir ${MSCOCO_DIR}
fi
# Inception v3 checkpoint file.
INCEPTION_CHECKPOINT="${HOME}/im2txt/data/inception_v3/inception_v3.ckpt"

# Directory to save the model.
MODEL_DIR="${HOME}/im2txt/model"

# Vocabulary file generated by the preprocessing script.
VOCAB_FILE="${HOME}/im2txt/data/mscoco/word_counts.txt"

# JPEG image file to caption.
IMAGE_FILE="${HOME}/im2txt/data/mscoco/raw-data/val2014/COCO_val2014_000000224477.jpg"


CHECKPOINT_PATH=
is_train=false
steps=1000000
gpu=1

#train  stage
# Run the training script.
cd ${HOME}

source ${py2env}
CUDA_VISIBLE_DEVICES=${gpu}  python -m im2txt.train  \
  --input_file_pattern="${MSCOCO_DIR}/train-?????-of-00256" \
  --inception_checkpoint_file="${INCEPTION_CHECKPOINT}" \
  --train_dir="${MODEL_DIR}/train" \
  --train_inception=${is_train} \
  --number_of_steps=${steps}


#evaluate
CUDA_VISIBLE_DEVICES=${gpu} python -m evaluate \
  --input_file_pattern="${MSCOCO_DIR}/val-?????-of-00004" \
  --checkpoint_dir="${MODEL_DIR}/train" \
  --eval_dir="${MODEL_DIR}/eval"


#inference stage
# Run inference to generate captions.
CUDA_VISIBLE_DEVICES=${gpu}  python -m  run_inference \
  --checkpoint_path=${CHECKPOINT_PATH} \
  --vocab_file=${VOCAB_FILE} \
  --input_files=${IMAGE_FILE}
